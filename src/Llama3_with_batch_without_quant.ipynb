{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451051c-58c7-4fde-ac50-50817a9b1691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce600131-1861-428d-9f94-a8ab8cca49ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 24 14:21:10 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:81:00.0 Off |                  N/A |\n",
      "|  0%   41C    P8             31W /  370W |   17654MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    144012      C   ....conda/envs/kg_pipeline/bin/python3      17644MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694413a-04f0-42ed-953c-a033bef36152",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 144012                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfa334e6-b915-4b34-a26b-e7d8f650539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import json\n",
    "import jsonlines\n",
    "import re\n",
    "import time\n",
    "\n",
    "torch.backends.cudnn.benchmark = True  # speedup\n",
    "\n",
    "def setup_model(model_id=\"meta-llama/Meta-Llama-3-8B\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    model.config.use_cache = False  # optional; can toggle True if preferred\n",
    "\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    return pipe, tokenizer\n",
    "\n",
    "def load_prompts(filepath):\n",
    "    with jsonlines.open(filepath) as reader:\n",
    "        return list(reader)\n",
    "\n",
    "def generate_text(generator, tokenizer, prompts, max_new_tokens=512):\n",
    "    input_lens = [tokenizer(p, return_tensors=\"pt\")['input_ids'].shape[1] for p in prompts]\n",
    "    max_tokens_batch = [min(2 * l, max_new_tokens) for l in input_lens]\n",
    "    max_new_tokens = max(max_tokens_batch) if max_tokens_batch else max_new_tokens\n",
    "\n",
    "    outputs = generator(\n",
    "        prompts,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        truncation=True,\n",
    "        num_return_sequences=2,\n",
    "        temperature=0.2,\n",
    "        top_p=0.9,\n",
    "        do_sample=True,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Flatten list of lists if pipeline returns nested list\n",
    "    if isinstance(outputs[0], list):\n",
    "        outputs = [item for sublist in outputs for item in sublist]\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "\n",
    "def extract_test_outputs(response):\n",
    "    outputs = []\n",
    "    if response and len(response) > 0:\n",
    "        for res in response:\n",
    "            generated_text = res.get('generated_text', '')\n",
    "            match = re.search(r'Test Output:\\s*(.*?)(?=\\n\\s*#|$)', generated_text, re.DOTALL)\n",
    "            if match:\n",
    "                outputs.append(match.group(1).strip())\n",
    "    return outputs if outputs else ['Output not found']\n",
    "\n",
    "def parse_model_output(model_output):\n",
    "    triples = []\n",
    "    lines = [line.strip() for line in model_output.strip().split('\\n') if line.strip()]\n",
    "    pattern = re.compile(r'(.+?)\\s*\\(([^,]+),\\s*([^)]+)\\)')\n",
    "    for line in lines:\n",
    "        for match in pattern.findall(line):\n",
    "            relation, subject, obj = match\n",
    "            triples.append({\n",
    "                \"sub\": subject.strip(),\n",
    "                \"rel\": relation.strip(),\n",
    "                \"obj\": obj.strip()\n",
    "            })\n",
    "    return triples\n",
    "\n",
    "def save_triples(processed_data, output_filepath):\n",
    "    with open(output_filepath, 'w', encoding='utf-8') as outfile:\n",
    "        for entry in processed_data:\n",
    "            json.dump({\"id\": entry[\"id\"], \"triples\": entry[\"triples\"]}, outfile, ensure_ascii=False)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "def main(jsonl_path, output_path, generator, tokenizer, num_prompts=548, batch_size=16):\n",
    "    prompts = load_prompts(jsonl_path)\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, min(num_prompts, len(prompts)), batch_size):\n",
    "        batch = prompts[i:i + batch_size]\n",
    "        batch_ids = [item['id'] for item in batch]\n",
    "        batch_prompts = [item['prompt'] for item in batch]\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            responses = generate_text(generator, tokenizer, batch_prompts)\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Batch {i}-{i+len(batch)-1} inference time: {elapsed:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in batch {i}-{i+batch_size}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # responses length = batch_size * num_return_sequences (2)\n",
    "        # group responses per prompt (2 each)\n",
    "        for idx in range(len(batch)):\n",
    "            # Each prompt has 2 responses: response at idx*2 and idx*2 + 1\n",
    "            prompt_responses = responses[2*idx:2*idx+2]\n",
    "\n",
    "            test_outputs = extract_test_outputs(prompt_responses)\n",
    "\n",
    "            all_triples = []\n",
    "            seen = set()\n",
    "            for test_output in test_outputs:\n",
    "                triples = parse_model_output(test_output)\n",
    "                for triple in triples:\n",
    "                    triple_key = (triple[\"sub\"], triple[\"rel\"], triple[\"obj\"])\n",
    "                    if triple_key not in seen:\n",
    "                        seen.add(triple_key)\n",
    "                        all_triples.append(triple)\n",
    "\n",
    "            print(f\"[{i + idx + 1}/{num_prompts}] ID: {batch_ids[idx]} → Unique triples extracted: {len(all_triples)}\")\n",
    "\n",
    "            results.append({\n",
    "                \"id\": batch_ids[idx],\n",
    "                \"triples\": all_triples\n",
    "            })\n",
    "\n",
    "    save_triples(results, output_path)\n",
    "    print(f\"\\n✅ All {len(results)} prompts processed. Results saved to: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197851a0-e308-4fb2-b092-de8bf74fc415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = '/upb/users/b/balram/profiles/unix/cs/Text2KG/withont/data/wikidata/input_prompts/cot_prompts/ont_9_nature_prompts_improved.jsonl'\n",
    "    output_file = \"/upb/users/b/balram/profiles/unix/cs/Text2KG/withont/data/wikidata/response/Llama3/cot_response_without_quant_batch/ont_9_nature_llm_response_improved.jsonl\"\n",
    "    text_pipe, tokenizer = setup_model(\"meta-llama/Meta-Llama-3-8B\")\n",
    "    main(input_file, output_file, text_pipe, tokenizer, num_prompts=1500, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35698b1-1cc8-4d1e-a8f0-dc4fb82c4be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c3e61-f3b5-4625-b31d-3caf2e7a574a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f3fd2-0795-4b48-8039-a90bff8ad1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d2683-ec61-438a-93f1-9bb560579628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d5bdd4-a1c3-4b51-9573-fe3dda98643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import json\n",
    "import jsonlines\n",
    "import re\n",
    "import time\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True  # speedup\n",
    "\n",
    "def setup_model(model_id=\"meta-llama/Meta-Llama-3-8B\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    model.config.use_cache = False  # optional; can toggle True if preferred\n",
    "\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    return pipe, tokenizer\n",
    "\n",
    "def load_prompts(filepath):\n",
    "    with jsonlines.open(filepath) as reader:\n",
    "        return list(reader)\n",
    "\n",
    "def generate_text(generator, tokenizer, prompts, max_new_tokens=512):\n",
    "    dataset = Dataset.from_dict({\"text\": prompts})\n",
    "    outputs = generator(\n",
    "        dataset[\"text\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        truncation=True,\n",
    "        num_return_sequences=2,\n",
    "        temperature=0.2,\n",
    "        top_p=0.9,\n",
    "        do_sample=True,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    # ✅ Flatten if it's a list of lists\n",
    "    if isinstance(outputs[0], list):\n",
    "        outputs = [item for sublist in outputs for item in sublist]\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def extract_test_outputs(response):\n",
    "    outputs = []\n",
    "    if response and len(response) > 0:\n",
    "        for res in response:\n",
    "            generated_text = res.get('generated_text', '')\n",
    "            match = re.search(r'Test Output:\\s*(.*?)(?=\\n\\s*#|$)', generated_text, re.DOTALL)\n",
    "            if match:\n",
    "                outputs.append(match.group(1).strip())\n",
    "    return outputs if outputs else ['Output not found']\n",
    "\n",
    "def parse_model_output(model_output):\n",
    "    triples = []\n",
    "    lines = [line.strip() for line in model_output.strip().split('\\n') if line.strip()]\n",
    "    pattern = re.compile(r'(.+?)\\s*\\(([^,]+),\\s*([^)]+)\\)')\n",
    "    for line in lines:\n",
    "        for match in pattern.findall(line):\n",
    "            relation, subject, obj = match\n",
    "            triples.append({\n",
    "                \"sub\": subject.strip(),\n",
    "                \"rel\": relation.strip(),\n",
    "                \"obj\": obj.strip()\n",
    "            })\n",
    "    return triples\n",
    "\n",
    "def save_triples(processed_data, output_filepath):\n",
    "    with open(output_filepath, 'w', encoding='utf-8') as outfile:\n",
    "        for entry in processed_data:\n",
    "            json.dump({\"id\": entry[\"id\"], \"triples\": entry[\"triples\"]}, outfile, ensure_ascii=False)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "def main(jsonl_path, output_path, generator, tokenizer, num_prompts=548, batch_size=16):\n",
    "    prompts = load_prompts(jsonl_path)\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, min(num_prompts, len(prompts)), batch_size):\n",
    "        batch = prompts[i:i + batch_size]\n",
    "        batch_ids = [item['id'] for item in batch]\n",
    "        batch_prompts = [item['prompt'] for item in batch]\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            responses = generate_text(generator, tokenizer, batch_prompts)\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Batch {i}-{i+len(batch)-1} inference time: {elapsed:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in batch {i}-{i+batch_size}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # responses length = batch_size * num_return_sequences (2)\n",
    "        # group responses per prompt (2 each)\n",
    "        for idx in range(len(batch)):\n",
    "            # Each prompt has 2 responses: response at idx*2 and idx*2 + 1\n",
    "            prompt_responses = responses[2*idx:2*idx+2]\n",
    "\n",
    "            test_outputs = extract_test_outputs(prompt_responses)\n",
    "\n",
    "            all_triples = []\n",
    "            seen = set()\n",
    "            for test_output in test_outputs:\n",
    "                triples = parse_model_output(test_output)\n",
    "                for triple in triples:\n",
    "                    triple_key = (triple[\"sub\"], triple[\"rel\"], triple[\"obj\"])\n",
    "                    if triple_key not in seen:\n",
    "                        seen.add(triple_key)\n",
    "                        all_triples.append(triple)\n",
    "\n",
    "            print(f\"[{i + idx + 1}/{num_prompts}] ID: {batch_ids[idx]} → Unique triples extracted: {len(all_triples)}\")\n",
    "\n",
    "            results.append({\n",
    "                \"id\": batch_ids[idx],\n",
    "                \"triples\": all_triples\n",
    "            })\n",
    "\n",
    "    save_triples(results, output_path)\n",
    "    print(f\"\\n✅ All {len(results)} prompts processed. Results saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed06597a-b5e7-4fc2-9cda-3e80fe08c942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.17it/s]\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0-7 inference time: 182.56 seconds\n",
      "[1/1500] ID: ont_4_book_test_1 → Unique triples extracted: 1\n",
      "[2/1500] ID: ont_4_book_test_2 → Unique triples extracted: 2\n",
      "[3/1500] ID: ont_4_book_test_3 → Unique triples extracted: 1\n",
      "[4/1500] ID: ont_4_book_test_4 → Unique triples extracted: 3\n",
      "[5/1500] ID: ont_4_book_test_5 → Unique triples extracted: 1\n",
      "[6/1500] ID: ont_4_book_test_6 → Unique triples extracted: 1\n",
      "[7/1500] ID: ont_4_book_test_7 → Unique triples extracted: 0\n",
      "[8/1500] ID: ont_4_book_test_8 → Unique triples extracted: 1\n",
      "Batch 8-15 inference time: 94.98 seconds\n",
      "[9/1500] ID: ont_4_book_test_9 → Unique triples extracted: 6\n",
      "[10/1500] ID: ont_4_book_test_10 → Unique triples extracted: 1\n",
      "[11/1500] ID: ont_4_book_test_11 → Unique triples extracted: 1\n",
      "[12/1500] ID: ont_4_book_test_12 → Unique triples extracted: 1\n",
      "[13/1500] ID: ont_4_book_test_13 → Unique triples extracted: 5\n",
      "[14/1500] ID: ont_4_book_test_14 → Unique triples extracted: 1\n",
      "[15/1500] ID: ont_4_book_test_15 → Unique triples extracted: 1\n",
      "[16/1500] ID: ont_4_book_test_16 → Unique triples extracted: 1\n",
      "Batch 16-23 inference time: 74.57 seconds\n",
      "[17/1500] ID: ont_4_book_test_17 → Unique triples extracted: 2\n",
      "[18/1500] ID: ont_4_book_test_18 → Unique triples extracted: 1\n",
      "[19/1500] ID: ont_4_book_test_19 → Unique triples extracted: 2\n",
      "[20/1500] ID: ont_4_book_test_20 → Unique triples extracted: 2\n",
      "[21/1500] ID: ont_4_book_test_21 → Unique triples extracted: 1\n",
      "[22/1500] ID: ont_4_book_test_22 → Unique triples extracted: 1\n",
      "[23/1500] ID: ont_4_book_test_23 → Unique triples extracted: 1\n",
      "[24/1500] ID: ont_4_book_test_24 → Unique triples extracted: 2\n",
      "Batch 24-31 inference time: 185.07 seconds\n",
      "[25/1500] ID: ont_4_book_test_25 → Unique triples extracted: 1\n",
      "[26/1500] ID: ont_4_book_test_26 → Unique triples extracted: 2\n",
      "[27/1500] ID: ont_4_book_test_27 → Unique triples extracted: 11\n",
      "[28/1500] ID: ont_4_book_test_28 → Unique triples extracted: 4\n",
      "[29/1500] ID: ont_4_book_test_29 → Unique triples extracted: 8\n",
      "[30/1500] ID: ont_4_book_test_30 → Unique triples extracted: 3\n",
      "[31/1500] ID: ont_4_book_test_31 → Unique triples extracted: 1\n",
      "[32/1500] ID: ont_4_book_test_32 → Unique triples extracted: 57\n",
      "Batch 32-39 inference time: 117.97 seconds\n",
      "[33/1500] ID: ont_4_book_test_33 → Unique triples extracted: 19\n",
      "[34/1500] ID: ont_4_book_test_34 → Unique triples extracted: 1\n",
      "[35/1500] ID: ont_4_book_test_35 → Unique triples extracted: 1\n",
      "[36/1500] ID: ont_4_book_test_36 → Unique triples extracted: 1\n",
      "[37/1500] ID: ont_4_book_test_37 → Unique triples extracted: 2\n",
      "[38/1500] ID: ont_4_book_test_38 → Unique triples extracted: 1\n",
      "[39/1500] ID: ont_4_book_test_39 → Unique triples extracted: 35\n",
      "[40/1500] ID: ont_4_book_test_40 → Unique triples extracted: 1\n",
      "Batch 40-47 inference time: 95.28 seconds\n",
      "[41/1500] ID: ont_4_book_test_41 → Unique triples extracted: 1\n",
      "[42/1500] ID: ont_4_book_test_42 → Unique triples extracted: 0\n",
      "[43/1500] ID: ont_4_book_test_43 → Unique triples extracted: 42\n",
      "[44/1500] ID: ont_4_book_test_44 → Unique triples extracted: 4\n",
      "[45/1500] ID: ont_4_book_test_45 → Unique triples extracted: 1\n",
      "[46/1500] ID: ont_4_book_test_46 → Unique triples extracted: 4\n",
      "[47/1500] ID: ont_4_book_test_47 → Unique triples extracted: 1\n",
      "[48/1500] ID: ont_4_book_test_48 → Unique triples extracted: 1\n",
      "Batch 48-55 inference time: 163.28 seconds\n",
      "[49/1500] ID: ont_4_book_test_49 → Unique triples extracted: 2\n",
      "[50/1500] ID: ont_4_book_test_50 → Unique triples extracted: 32\n",
      "[51/1500] ID: ont_4_book_test_51 → Unique triples extracted: 38\n",
      "[52/1500] ID: ont_4_book_test_52 → Unique triples extracted: 1\n",
      "[53/1500] ID: ont_4_book_test_53 → Unique triples extracted: 2\n",
      "[54/1500] ID: ont_4_book_test_54 → Unique triples extracted: 7\n",
      "[55/1500] ID: ont_4_book_test_55 → Unique triples extracted: 8\n",
      "[56/1500] ID: ont_4_book_test_56 → Unique triples extracted: 2\n",
      "Batch 56-63 inference time: 163.73 seconds\n",
      "[57/1500] ID: ont_4_book_test_57 → Unique triples extracted: 5\n",
      "[58/1500] ID: ont_4_book_test_58 → Unique triples extracted: 3\n",
      "[59/1500] ID: ont_4_book_test_59 → Unique triples extracted: 3\n",
      "[60/1500] ID: ont_4_book_test_60 → Unique triples extracted: 1\n",
      "[61/1500] ID: ont_4_book_test_61 → Unique triples extracted: 1\n",
      "[62/1500] ID: ont_4_book_test_62 → Unique triples extracted: 2\n",
      "[63/1500] ID: ont_4_book_test_63 → Unique triples extracted: 1\n",
      "[64/1500] ID: ont_4_book_test_64 → Unique triples extracted: 1\n",
      "Batch 64-71 inference time: 162.42 seconds\n",
      "[65/1500] ID: ont_4_book_test_65 → Unique triples extracted: 1\n",
      "[66/1500] ID: ont_4_book_test_66 → Unique triples extracted: 2\n",
      "[67/1500] ID: ont_4_book_test_67 → Unique triples extracted: 1\n",
      "[68/1500] ID: ont_4_book_test_68 → Unique triples extracted: 0\n",
      "[69/1500] ID: ont_4_book_test_69 → Unique triples extracted: 3\n",
      "[70/1500] ID: ont_4_book_test_70 → Unique triples extracted: 1\n",
      "[71/1500] ID: ont_4_book_test_71 → Unique triples extracted: 1\n",
      "[72/1500] ID: ont_4_book_test_72 → Unique triples extracted: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 72-79 inference time: 141.09 seconds\n",
      "[73/1500] ID: ont_4_book_test_73 → Unique triples extracted: 2\n",
      "[74/1500] ID: ont_4_book_test_74 → Unique triples extracted: 1\n",
      "[75/1500] ID: ont_4_book_test_75 → Unique triples extracted: 1\n",
      "[76/1500] ID: ont_4_book_test_76 → Unique triples extracted: 1\n",
      "[77/1500] ID: ont_4_book_test_77 → Unique triples extracted: 1\n",
      "[78/1500] ID: ont_4_book_test_78 → Unique triples extracted: 1\n",
      "[79/1500] ID: ont_4_book_test_79 → Unique triples extracted: 1\n",
      "[80/1500] ID: ont_4_book_test_80 → Unique triples extracted: 4\n",
      "Batch 80-87 inference time: 159.85 seconds\n",
      "[81/1500] ID: ont_4_book_test_81 → Unique triples extracted: 3\n",
      "[82/1500] ID: ont_4_book_test_82 → Unique triples extracted: 9\n",
      "[83/1500] ID: ont_4_book_test_83 → Unique triples extracted: 1\n",
      "[84/1500] ID: ont_4_book_test_84 → Unique triples extracted: 0\n",
      "[85/1500] ID: ont_4_book_test_85 → Unique triples extracted: 0\n",
      "[86/1500] ID: ont_4_book_test_86 → Unique triples extracted: 1\n",
      "[87/1500] ID: ont_4_book_test_87 → Unique triples extracted: 1\n",
      "[88/1500] ID: ont_4_book_test_88 → Unique triples extracted: 19\n",
      "Batch 88-95 inference time: 181.97 seconds\n",
      "[89/1500] ID: ont_4_book_test_89 → Unique triples extracted: 4\n",
      "[90/1500] ID: ont_4_book_test_90 → Unique triples extracted: 6\n",
      "[91/1500] ID: ont_4_book_test_91 → Unique triples extracted: 1\n",
      "[92/1500] ID: ont_4_book_test_92 → Unique triples extracted: 3\n",
      "[93/1500] ID: ont_4_book_test_93 → Unique triples extracted: 1\n",
      "[94/1500] ID: ont_4_book_test_94 → Unique triples extracted: 3\n",
      "[95/1500] ID: ont_4_book_test_95 → Unique triples extracted: 1\n",
      "[96/1500] ID: ont_4_book_test_96 → Unique triples extracted: 1\n",
      "Batch 96-103 inference time: 160.15 seconds\n",
      "[97/1500] ID: ont_4_book_test_97 → Unique triples extracted: 1\n",
      "[98/1500] ID: ont_4_book_test_98 → Unique triples extracted: 4\n",
      "[99/1500] ID: ont_4_book_test_99 → Unique triples extracted: 2\n",
      "[100/1500] ID: ont_4_book_test_100 → Unique triples extracted: 1\n",
      "[101/1500] ID: ont_4_book_test_101 → Unique triples extracted: 1\n",
      "[102/1500] ID: ont_4_book_test_102 → Unique triples extracted: 5\n",
      "[103/1500] ID: ont_4_book_test_103 → Unique triples extracted: 2\n",
      "[104/1500] ID: ont_4_book_test_104 → Unique triples extracted: 2\n",
      "Batch 104-111 inference time: 116.71 seconds\n",
      "[105/1500] ID: ont_4_book_test_105 → Unique triples extracted: 2\n",
      "[106/1500] ID: ont_4_book_test_106 → Unique triples extracted: 1\n",
      "[107/1500] ID: ont_4_book_test_107 → Unique triples extracted: 2\n",
      "[108/1500] ID: ont_4_book_test_108 → Unique triples extracted: 2\n",
      "[109/1500] ID: ont_4_book_test_109 → Unique triples extracted: 3\n",
      "[110/1500] ID: ont_4_book_test_110 → Unique triples extracted: 0\n",
      "[111/1500] ID: ont_4_book_test_111 → Unique triples extracted: 0\n",
      "[112/1500] ID: ont_4_book_test_112 → Unique triples extracted: 2\n",
      "Batch 112-119 inference time: 119.18 seconds\n",
      "[113/1500] ID: ont_4_book_test_113 → Unique triples extracted: 3\n",
      "[114/1500] ID: ont_4_book_test_114 → Unique triples extracted: 2\n",
      "[115/1500] ID: ont_4_book_test_115 → Unique triples extracted: 46\n",
      "[116/1500] ID: ont_4_book_test_116 → Unique triples extracted: 1\n",
      "[117/1500] ID: ont_4_book_test_117 → Unique triples extracted: 6\n",
      "[118/1500] ID: ont_4_book_test_118 → Unique triples extracted: 1\n",
      "[119/1500] ID: ont_4_book_test_119 → Unique triples extracted: 1\n",
      "[120/1500] ID: ont_4_book_test_120 → Unique triples extracted: 1\n",
      "Batch 120-127 inference time: 118.58 seconds\n",
      "[121/1500] ID: ont_4_book_test_121 → Unique triples extracted: 3\n",
      "[122/1500] ID: ont_4_book_test_122 → Unique triples extracted: 1\n",
      "[123/1500] ID: ont_4_book_test_123 → Unique triples extracted: 2\n",
      "[124/1500] ID: ont_4_book_test_124 → Unique triples extracted: 6\n",
      "[125/1500] ID: ont_4_book_test_125 → Unique triples extracted: 4\n",
      "[126/1500] ID: ont_4_book_test_126 → Unique triples extracted: 1\n",
      "[127/1500] ID: ont_4_book_test_127 → Unique triples extracted: 1\n",
      "[128/1500] ID: ont_4_book_test_128 → Unique triples extracted: 1\n",
      "Batch 128-135 inference time: 140.56 seconds\n",
      "[129/1500] ID: ont_4_book_test_129 → Unique triples extracted: 1\n",
      "[130/1500] ID: ont_4_book_test_130 → Unique triples extracted: 28\n",
      "[131/1500] ID: ont_4_book_test_131 → Unique triples extracted: 8\n",
      "[132/1500] ID: ont_4_book_test_132 → Unique triples extracted: 1\n",
      "[133/1500] ID: ont_4_book_test_133 → Unique triples extracted: 13\n",
      "[134/1500] ID: ont_4_book_test_134 → Unique triples extracted: 1\n",
      "[135/1500] ID: ont_4_book_test_135 → Unique triples extracted: 1\n",
      "[136/1500] ID: ont_4_book_test_136 → Unique triples extracted: 1\n",
      "Batch 136-143 inference time: 159.17 seconds\n",
      "[137/1500] ID: ont_4_book_test_137 → Unique triples extracted: 1\n",
      "[138/1500] ID: ont_4_book_test_138 → Unique triples extracted: 0\n",
      "[139/1500] ID: ont_4_book_test_139 → Unique triples extracted: 2\n",
      "[140/1500] ID: ont_4_book_test_140 → Unique triples extracted: 1\n",
      "[141/1500] ID: ont_4_book_test_141 → Unique triples extracted: 2\n",
      "[142/1500] ID: ont_4_book_test_142 → Unique triples extracted: 5\n",
      "[143/1500] ID: ont_4_book_test_143 → Unique triples extracted: 2\n",
      "[144/1500] ID: ont_4_book_test_144 → Unique triples extracted: 1\n",
      "Batch 144-151 inference time: 121.08 seconds\n",
      "[145/1500] ID: ont_4_book_test_145 → Unique triples extracted: 1\n",
      "[146/1500] ID: ont_4_book_test_146 → Unique triples extracted: 6\n",
      "[147/1500] ID: ont_4_book_test_147 → Unique triples extracted: 1\n",
      "[148/1500] ID: ont_4_book_test_148 → Unique triples extracted: 3\n",
      "[149/1500] ID: ont_4_book_test_149 → Unique triples extracted: 5\n",
      "[150/1500] ID: ont_4_book_test_150 → Unique triples extracted: 1\n",
      "[151/1500] ID: ont_4_book_test_151 → Unique triples extracted: 2\n",
      "[152/1500] ID: ont_4_book_test_152 → Unique triples extracted: 3\n",
      "Batch 152-159 inference time: 160.18 seconds\n",
      "[153/1500] ID: ont_4_book_test_153 → Unique triples extracted: 2\n",
      "[154/1500] ID: ont_4_book_test_154 → Unique triples extracted: 2\n",
      "[155/1500] ID: ont_4_book_test_155 → Unique triples extracted: 10\n",
      "[156/1500] ID: ont_4_book_test_156 → Unique triples extracted: 1\n",
      "[157/1500] ID: ont_4_book_test_157 → Unique triples extracted: 1\n",
      "[158/1500] ID: ont_4_book_test_158 → Unique triples extracted: 3\n",
      "[159/1500] ID: ont_4_book_test_159 → Unique triples extracted: 1\n",
      "[160/1500] ID: ont_4_book_test_160 → Unique triples extracted: 8\n",
      "Batch 160-167 inference time: 137.03 seconds\n",
      "[161/1500] ID: ont_4_book_test_161 → Unique triples extracted: 1\n",
      "[162/1500] ID: ont_4_book_test_162 → Unique triples extracted: 2\n",
      "[163/1500] ID: ont_4_book_test_163 → Unique triples extracted: 1\n",
      "[164/1500] ID: ont_4_book_test_164 → Unique triples extracted: 2\n",
      "[165/1500] ID: ont_4_book_test_165 → Unique triples extracted: 8\n",
      "[166/1500] ID: ont_4_book_test_166 → Unique triples extracted: 1\n",
      "[167/1500] ID: ont_4_book_test_167 → Unique triples extracted: 6\n",
      "[168/1500] ID: ont_4_book_test_168 → Unique triples extracted: 4\n",
      "Batch 168-175 inference time: 115.77 seconds\n",
      "[169/1500] ID: ont_4_book_test_169 → Unique triples extracted: 1\n",
      "[170/1500] ID: ont_4_book_test_170 → Unique triples extracted: 2\n",
      "[171/1500] ID: ont_4_book_test_171 → Unique triples extracted: 2\n",
      "[172/1500] ID: ont_4_book_test_172 → Unique triples extracted: 15\n",
      "[173/1500] ID: ont_4_book_test_173 → Unique triples extracted: 21\n",
      "[174/1500] ID: ont_4_book_test_174 → Unique triples extracted: 1\n",
      "[175/1500] ID: ont_4_book_test_175 → Unique triples extracted: 1\n",
      "[176/1500] ID: ont_4_book_test_176 → Unique triples extracted: 1\n",
      "Batch 176-183 inference time: 136.79 seconds\n",
      "[177/1500] ID: ont_4_book_test_177 → Unique triples extracted: 1\n",
      "[178/1500] ID: ont_4_book_test_178 → Unique triples extracted: 6\n",
      "[179/1500] ID: ont_4_book_test_179 → Unique triples extracted: 5\n",
      "[180/1500] ID: ont_4_book_test_180 → Unique triples extracted: 1\n",
      "[181/1500] ID: ont_4_book_test_181 → Unique triples extracted: 1\n",
      "[182/1500] ID: ont_4_book_test_182 → Unique triples extracted: 1\n",
      "[183/1500] ID: ont_4_book_test_183 → Unique triples extracted: 1\n",
      "[184/1500] ID: ont_4_book_test_184 → Unique triples extracted: 4\n",
      "Batch 184-191 inference time: 160.58 seconds\n",
      "[185/1500] ID: ont_4_book_test_185 → Unique triples extracted: 1\n",
      "[186/1500] ID: ont_4_book_test_186 → Unique triples extracted: 20\n",
      "[187/1500] ID: ont_4_book_test_187 → Unique triples extracted: 1\n",
      "[188/1500] ID: ont_4_book_test_188 → Unique triples extracted: 1\n",
      "[189/1500] ID: ont_4_book_test_189 → Unique triples extracted: 5\n",
      "[190/1500] ID: ont_4_book_test_190 → Unique triples extracted: 5\n",
      "[191/1500] ID: ont_4_book_test_191 → Unique triples extracted: 1\n",
      "[192/1500] ID: ont_4_book_test_192 → Unique triples extracted: 1\n",
      "Batch 192-199 inference time: 99.33 seconds\n",
      "[193/1500] ID: ont_4_book_test_193 → Unique triples extracted: 1\n",
      "[194/1500] ID: ont_4_book_test_194 → Unique triples extracted: 39\n",
      "[195/1500] ID: ont_4_book_test_195 → Unique triples extracted: 3\n",
      "[196/1500] ID: ont_4_book_test_196 → Unique triples extracted: 1\n",
      "[197/1500] ID: ont_4_book_test_197 → Unique triples extracted: 1\n",
      "[198/1500] ID: ont_4_book_test_198 → Unique triples extracted: 1\n",
      "[199/1500] ID: ont_4_book_test_199 → Unique triples extracted: 1\n",
      "[200/1500] ID: ont_4_book_test_200 → Unique triples extracted: 1\n",
      "Batch 200-207 inference time: 115.15 seconds\n",
      "[201/1500] ID: ont_4_book_test_201 → Unique triples extracted: 2\n",
      "[202/1500] ID: ont_4_book_test_202 → Unique triples extracted: 11\n",
      "[203/1500] ID: ont_4_book_test_203 → Unique triples extracted: 5\n",
      "[204/1500] ID: ont_4_book_test_204 → Unique triples extracted: 1\n",
      "[205/1500] ID: ont_4_book_test_205 → Unique triples extracted: 28\n",
      "[206/1500] ID: ont_4_book_test_206 → Unique triples extracted: 1\n",
      "[207/1500] ID: ont_4_book_test_207 → Unique triples extracted: 1\n",
      "[208/1500] ID: ont_4_book_test_208 → Unique triples extracted: 1\n",
      "Batch 208-215 inference time: 159.49 seconds\n",
      "[209/1500] ID: ont_4_book_test_209 → Unique triples extracted: 1\n",
      "[210/1500] ID: ont_4_book_test_210 → Unique triples extracted: 37\n",
      "[211/1500] ID: ont_4_book_test_211 → Unique triples extracted: 5\n",
      "[212/1500] ID: ont_4_book_test_212 → Unique triples extracted: 4\n",
      "[213/1500] ID: ont_4_book_test_213 → Unique triples extracted: 3\n",
      "[214/1500] ID: ont_4_book_test_214 → Unique triples extracted: 1\n",
      "[215/1500] ID: ont_4_book_test_215 → Unique triples extracted: 1\n",
      "[216/1500] ID: ont_4_book_test_216 → Unique triples extracted: 19\n",
      "Batch 216-223 inference time: 118.55 seconds\n",
      "[217/1500] ID: ont_4_book_test_217 → Unique triples extracted: 2\n",
      "[218/1500] ID: ont_4_book_test_218 → Unique triples extracted: 1\n",
      "[219/1500] ID: ont_4_book_test_219 → Unique triples extracted: 1\n",
      "[220/1500] ID: ont_4_book_test_220 → Unique triples extracted: 1\n",
      "[221/1500] ID: ont_4_book_test_221 → Unique triples extracted: 1\n",
      "[222/1500] ID: ont_4_book_test_222 → Unique triples extracted: 1\n",
      "[223/1500] ID: ont_4_book_test_223 → Unique triples extracted: 1\n",
      "[224/1500] ID: ont_4_book_test_224 → Unique triples extracted: 1\n",
      "Batch 224-231 inference time: 159.03 seconds\n",
      "[225/1500] ID: ont_4_book_test_225 → Unique triples extracted: 1\n",
      "[226/1500] ID: ont_4_book_test_226 → Unique triples extracted: 2\n",
      "[227/1500] ID: ont_4_book_test_227 → Unique triples extracted: 1\n",
      "[228/1500] ID: ont_4_book_test_228 → Unique triples extracted: 1\n",
      "[229/1500] ID: ont_4_book_test_229 → Unique triples extracted: 8\n",
      "[230/1500] ID: ont_4_book_test_230 → Unique triples extracted: 1\n",
      "[231/1500] ID: ont_4_book_test_231 → Unique triples extracted: 2\n",
      "[232/1500] ID: ont_4_book_test_232 → Unique triples extracted: 3\n",
      "Batch 232-239 inference time: 160.55 seconds\n",
      "[233/1500] ID: ont_4_book_test_233 → Unique triples extracted: 4\n",
      "[234/1500] ID: ont_4_book_test_234 → Unique triples extracted: 1\n",
      "[235/1500] ID: ont_4_book_test_235 → Unique triples extracted: 1\n",
      "[236/1500] ID: ont_4_book_test_236 → Unique triples extracted: 2\n",
      "[237/1500] ID: ont_4_book_test_237 → Unique triples extracted: 1\n",
      "[238/1500] ID: ont_4_book_test_238 → Unique triples extracted: 6\n",
      "[239/1500] ID: ont_4_book_test_239 → Unique triples extracted: 3\n",
      "[240/1500] ID: ont_4_book_test_240 → Unique triples extracted: 7\n",
      "Batch 240-247 inference time: 159.21 seconds\n",
      "[241/1500] ID: ont_4_book_test_241 → Unique triples extracted: 1\n",
      "[242/1500] ID: ont_4_book_test_242 → Unique triples extracted: 1\n",
      "[243/1500] ID: ont_4_book_test_243 → Unique triples extracted: 0\n",
      "[244/1500] ID: ont_4_book_test_244 → Unique triples extracted: 1\n",
      "[245/1500] ID: ont_4_book_test_245 → Unique triples extracted: 2\n",
      "[246/1500] ID: ont_4_book_test_246 → Unique triples extracted: 2\n",
      "[247/1500] ID: ont_4_book_test_247 → Unique triples extracted: 3\n",
      "[248/1500] ID: ont_4_book_test_248 → Unique triples extracted: 3\n",
      "Batch 248-255 inference time: 116.46 seconds\n",
      "[249/1500] ID: ont_4_book_test_249 → Unique triples extracted: 1\n",
      "[250/1500] ID: ont_4_book_test_250 → Unique triples extracted: 2\n",
      "[251/1500] ID: ont_4_book_test_251 → Unique triples extracted: 1\n",
      "[252/1500] ID: ont_4_book_test_252 → Unique triples extracted: 1\n",
      "[253/1500] ID: ont_4_book_test_253 → Unique triples extracted: 1\n",
      "[254/1500] ID: ont_4_book_test_254 → Unique triples extracted: 1\n",
      "[255/1500] ID: ont_4_book_test_255 → Unique triples extracted: 1\n",
      "[256/1500] ID: ont_4_book_test_256 → Unique triples extracted: 1\n",
      "Batch 256-263 inference time: 118.07 seconds\n",
      "[257/1500] ID: ont_4_book_test_257 → Unique triples extracted: 1\n",
      "[258/1500] ID: ont_4_book_test_258 → Unique triples extracted: 40\n",
      "[259/1500] ID: ont_4_book_test_259 → Unique triples extracted: 1\n",
      "[260/1500] ID: ont_4_book_test_260 → Unique triples extracted: 1\n",
      "[261/1500] ID: ont_4_book_test_261 → Unique triples extracted: 3\n",
      "[262/1500] ID: ont_4_book_test_262 → Unique triples extracted: 1\n",
      "[263/1500] ID: ont_4_book_test_263 → Unique triples extracted: 2\n",
      "[264/1500] ID: ont_4_book_test_264 → Unique triples extracted: 3\n",
      "Batch 264-271 inference time: 181.54 seconds\n",
      "[265/1500] ID: ont_4_book_test_265 → Unique triples extracted: 1\n",
      "[266/1500] ID: ont_4_book_test_266 → Unique triples extracted: 1\n",
      "[267/1500] ID: ont_4_book_test_267 → Unique triples extracted: 1\n",
      "[268/1500] ID: ont_4_book_test_268 → Unique triples extracted: 1\n",
      "[269/1500] ID: ont_4_book_test_269 → Unique triples extracted: 1\n",
      "[270/1500] ID: ont_4_book_test_270 → Unique triples extracted: 1\n",
      "[271/1500] ID: ont_4_book_test_271 → Unique triples extracted: 2\n",
      "[272/1500] ID: ont_4_book_test_272 → Unique triples extracted: 7\n",
      "Batch 272-279 inference time: 93.56 seconds\n",
      "[273/1500] ID: ont_4_book_test_273 → Unique triples extracted: 10\n",
      "[274/1500] ID: ont_4_book_test_274 → Unique triples extracted: 1\n",
      "[275/1500] ID: ont_4_book_test_275 → Unique triples extracted: 1\n",
      "[276/1500] ID: ont_4_book_test_276 → Unique triples extracted: 1\n",
      "[277/1500] ID: ont_4_book_test_277 → Unique triples extracted: 1\n",
      "[278/1500] ID: ont_4_book_test_278 → Unique triples extracted: 6\n",
      "[279/1500] ID: ont_4_book_test_279 → Unique triples extracted: 1\n",
      "[280/1500] ID: ont_4_book_test_280 → Unique triples extracted: 4\n",
      "Batch 280-287 inference time: 139.33 seconds\n",
      "[281/1500] ID: ont_4_book_test_281 → Unique triples extracted: 3\n",
      "[282/1500] ID: ont_4_book_test_282 → Unique triples extracted: 1\n",
      "[283/1500] ID: ont_4_book_test_283 → Unique triples extracted: 8\n",
      "[284/1500] ID: ont_4_book_test_284 → Unique triples extracted: 3\n",
      "[285/1500] ID: ont_4_book_test_285 → Unique triples extracted: 1\n",
      "[286/1500] ID: ont_4_book_test_286 → Unique triples extracted: 2\n",
      "[287/1500] ID: ont_4_book_test_287 → Unique triples extracted: 5\n",
      "[288/1500] ID: ont_4_book_test_288 → Unique triples extracted: 7\n",
      "Batch 288-295 inference time: 159.67 seconds\n",
      "[289/1500] ID: ont_4_book_test_289 → Unique triples extracted: 16\n",
      "[290/1500] ID: ont_4_book_test_290 → Unique triples extracted: 3\n",
      "[291/1500] ID: ont_4_book_test_291 → Unique triples extracted: 1\n",
      "[292/1500] ID: ont_4_book_test_292 → Unique triples extracted: 1\n",
      "[293/1500] ID: ont_4_book_test_293 → Unique triples extracted: 1\n",
      "[294/1500] ID: ont_4_book_test_294 → Unique triples extracted: 1\n",
      "[295/1500] ID: ont_4_book_test_295 → Unique triples extracted: 1\n",
      "[296/1500] ID: ont_4_book_test_296 → Unique triples extracted: 13\n",
      "Batch 296-303 inference time: 138.07 seconds\n",
      "[297/1500] ID: ont_4_book_test_297 → Unique triples extracted: 1\n",
      "[298/1500] ID: ont_4_book_test_298 → Unique triples extracted: 23\n",
      "[299/1500] ID: ont_4_book_test_299 → Unique triples extracted: 10\n",
      "[300/1500] ID: ont_4_book_test_300 → Unique triples extracted: 5\n",
      "[301/1500] ID: ont_4_book_test_301 → Unique triples extracted: 1\n",
      "[302/1500] ID: ont_4_book_test_302 → Unique triples extracted: 5\n",
      "[303/1500] ID: ont_4_book_test_303 → Unique triples extracted: 5\n",
      "[304/1500] ID: ont_4_book_test_304 → Unique triples extracted: 1\n",
      "Batch 304-311 inference time: 138.82 seconds\n",
      "[305/1500] ID: ont_4_book_test_305 → Unique triples extracted: 1\n",
      "[306/1500] ID: ont_4_book_test_306 → Unique triples extracted: 1\n",
      "[307/1500] ID: ont_4_book_test_307 → Unique triples extracted: 5\n",
      "[308/1500] ID: ont_4_book_test_308 → Unique triples extracted: 12\n",
      "[309/1500] ID: ont_4_book_test_309 → Unique triples extracted: 3\n",
      "[310/1500] ID: ont_4_book_test_310 → Unique triples extracted: 5\n",
      "[311/1500] ID: ont_4_book_test_311 → Unique triples extracted: 8\n",
      "[312/1500] ID: ont_4_book_test_312 → Unique triples extracted: 6\n",
      "Batch 312-319 inference time: 137.98 seconds\n",
      "[313/1500] ID: ont_4_book_test_313 → Unique triples extracted: 7\n",
      "[314/1500] ID: ont_4_book_test_314 → Unique triples extracted: 1\n",
      "[315/1500] ID: ont_4_book_test_315 → Unique triples extracted: 4\n",
      "[316/1500] ID: ont_4_book_test_316 → Unique triples extracted: 3\n",
      "[317/1500] ID: ont_4_book_test_317 → Unique triples extracted: 1\n",
      "[318/1500] ID: ont_4_book_test_318 → Unique triples extracted: 1\n",
      "[319/1500] ID: ont_4_book_test_319 → Unique triples extracted: 1\n",
      "[320/1500] ID: ont_4_book_test_320 → Unique triples extracted: 5\n",
      "Batch 320-327 inference time: 160.29 seconds\n",
      "[321/1500] ID: ont_4_book_test_321 → Unique triples extracted: 5\n",
      "[322/1500] ID: ont_4_book_test_322 → Unique triples extracted: 2\n",
      "[323/1500] ID: ont_4_book_test_323 → Unique triples extracted: 1\n",
      "[324/1500] ID: ont_4_book_test_324 → Unique triples extracted: 6\n",
      "[325/1500] ID: ont_4_book_test_325 → Unique triples extracted: 1\n",
      "[326/1500] ID: ont_4_book_test_326 → Unique triples extracted: 54\n",
      "[327/1500] ID: ont_4_book_test_327 → Unique triples extracted: 1\n",
      "[328/1500] ID: ont_4_book_test_328 → Unique triples extracted: 3\n",
      "Batch 328-335 inference time: 181.69 seconds\n",
      "[329/1500] ID: ont_4_book_test_329 → Unique triples extracted: 1\n",
      "[330/1500] ID: ont_4_book_test_330 → Unique triples extracted: 0\n",
      "[331/1500] ID: ont_4_book_test_331 → Unique triples extracted: 1\n",
      "[332/1500] ID: ont_4_book_test_332 → Unique triples extracted: 1\n",
      "[333/1500] ID: ont_4_book_test_333 → Unique triples extracted: 1\n",
      "[334/1500] ID: ont_4_book_test_334 → Unique triples extracted: 1\n",
      "[335/1500] ID: ont_4_book_test_335 → Unique triples extracted: 1\n",
      "[336/1500] ID: ont_4_book_test_336 → Unique triples extracted: 1\n",
      "Batch 336-343 inference time: 93.70 seconds\n",
      "[337/1500] ID: ont_4_book_test_337 → Unique triples extracted: 1\n",
      "[338/1500] ID: ont_4_book_test_338 → Unique triples extracted: 1\n",
      "[339/1500] ID: ont_4_book_test_339 → Unique triples extracted: 1\n",
      "[340/1500] ID: ont_4_book_test_340 → Unique triples extracted: 12\n",
      "[341/1500] ID: ont_4_book_test_341 → Unique triples extracted: 1\n",
      "[342/1500] ID: ont_4_book_test_342 → Unique triples extracted: 2\n",
      "[343/1500] ID: ont_4_book_test_343 → Unique triples extracted: 1\n",
      "[344/1500] ID: ont_4_book_test_344 → Unique triples extracted: 1\n",
      "Batch 344-351 inference time: 180.72 seconds\n",
      "[345/1500] ID: ont_4_book_test_345 → Unique triples extracted: 2\n",
      "[346/1500] ID: ont_4_book_test_346 → Unique triples extracted: 4\n",
      "[347/1500] ID: ont_4_book_test_347 → Unique triples extracted: 1\n",
      "[348/1500] ID: ont_4_book_test_348 → Unique triples extracted: 1\n",
      "[349/1500] ID: ont_4_book_test_349 → Unique triples extracted: 1\n",
      "[350/1500] ID: ont_4_book_test_350 → Unique triples extracted: 1\n",
      "[351/1500] ID: ont_4_book_test_351 → Unique triples extracted: 2\n",
      "[352/1500] ID: ont_4_book_test_352 → Unique triples extracted: 12\n",
      "Batch 352-359 inference time: 181.06 seconds\n",
      "[353/1500] ID: ont_4_book_test_353 → Unique triples extracted: 2\n",
      "[354/1500] ID: ont_4_book_test_354 → Unique triples extracted: 2\n",
      "[355/1500] ID: ont_4_book_test_355 → Unique triples extracted: 2\n",
      "[356/1500] ID: ont_4_book_test_356 → Unique triples extracted: 1\n",
      "[357/1500] ID: ont_4_book_test_357 → Unique triples extracted: 1\n",
      "[358/1500] ID: ont_4_book_test_358 → Unique triples extracted: 1\n",
      "[359/1500] ID: ont_4_book_test_359 → Unique triples extracted: 1\n",
      "[360/1500] ID: ont_4_book_test_360 → Unique triples extracted: 1\n",
      "Batch 360-367 inference time: 137.38 seconds\n",
      "[361/1500] ID: ont_4_book_test_361 → Unique triples extracted: 1\n",
      "[362/1500] ID: ont_4_book_test_362 → Unique triples extracted: 1\n",
      "[363/1500] ID: ont_4_book_test_363 → Unique triples extracted: 4\n",
      "[364/1500] ID: ont_4_book_test_364 → Unique triples extracted: 1\n",
      "[365/1500] ID: ont_4_book_test_365 → Unique triples extracted: 1\n",
      "[366/1500] ID: ont_4_book_test_366 → Unique triples extracted: 1\n",
      "[367/1500] ID: ont_4_book_test_367 → Unique triples extracted: 1\n",
      "[368/1500] ID: ont_4_book_test_368 → Unique triples extracted: 1\n",
      "Batch 368-375 inference time: 181.09 seconds\n",
      "[369/1500] ID: ont_4_book_test_369 → Unique triples extracted: 2\n",
      "[370/1500] ID: ont_4_book_test_370 → Unique triples extracted: 3\n",
      "[371/1500] ID: ont_4_book_test_371 → Unique triples extracted: 5\n",
      "[372/1500] ID: ont_4_book_test_372 → Unique triples extracted: 1\n",
      "[373/1500] ID: ont_4_book_test_373 → Unique triples extracted: 1\n",
      "[374/1500] ID: ont_4_book_test_374 → Unique triples extracted: 1\n",
      "[375/1500] ID: ont_4_book_test_375 → Unique triples extracted: 0\n",
      "[376/1500] ID: ont_4_book_test_376 → Unique triples extracted: 5\n",
      "Batch 376-383 inference time: 182.10 seconds\n",
      "[377/1500] ID: ont_4_book_test_377 → Unique triples extracted: 1\n",
      "[378/1500] ID: ont_4_book_test_378 → Unique triples extracted: 1\n",
      "[379/1500] ID: ont_4_book_test_379 → Unique triples extracted: 1\n",
      "[380/1500] ID: ont_4_book_test_380 → Unique triples extracted: 1\n",
      "[381/1500] ID: ont_4_book_test_381 → Unique triples extracted: 2\n",
      "[382/1500] ID: ont_4_book_test_382 → Unique triples extracted: 6\n",
      "[383/1500] ID: ont_4_book_test_383 → Unique triples extracted: 1\n",
      "[384/1500] ID: ont_4_book_test_384 → Unique triples extracted: 1\n",
      "Batch 384-391 inference time: 137.89 seconds\n",
      "[385/1500] ID: ont_4_book_test_385 → Unique triples extracted: 1\n",
      "[386/1500] ID: ont_4_book_test_386 → Unique triples extracted: 4\n",
      "[387/1500] ID: ont_4_book_test_387 → Unique triples extracted: 3\n",
      "[388/1500] ID: ont_4_book_test_388 → Unique triples extracted: 1\n",
      "[389/1500] ID: ont_4_book_test_389 → Unique triples extracted: 2\n",
      "[390/1500] ID: ont_4_book_test_390 → Unique triples extracted: 15\n",
      "[391/1500] ID: ont_4_book_test_391 → Unique triples extracted: 9\n",
      "[392/1500] ID: ont_4_book_test_392 → Unique triples extracted: 4\n",
      "Batch 392-399 inference time: 181.23 seconds\n",
      "[393/1500] ID: ont_4_book_test_393 → Unique triples extracted: 12\n",
      "[394/1500] ID: ont_4_book_test_394 → Unique triples extracted: 8\n",
      "[395/1500] ID: ont_4_book_test_395 → Unique triples extracted: 1\n",
      "[396/1500] ID: ont_4_book_test_396 → Unique triples extracted: 1\n",
      "[397/1500] ID: ont_4_book_test_397 → Unique triples extracted: 3\n",
      "[398/1500] ID: ont_4_book_test_398 → Unique triples extracted: 8\n",
      "[399/1500] ID: ont_4_book_test_399 → Unique triples extracted: 1\n",
      "[400/1500] ID: ont_4_book_test_400 → Unique triples extracted: 1\n",
      "Batch 400-407 inference time: 159.44 seconds\n",
      "[401/1500] ID: ont_4_book_test_401 → Unique triples extracted: 4\n",
      "[402/1500] ID: ont_4_book_test_402 → Unique triples extracted: 1\n",
      "[403/1500] ID: ont_4_book_test_403 → Unique triples extracted: 2\n",
      "[404/1500] ID: ont_4_book_test_404 → Unique triples extracted: 1\n",
      "[405/1500] ID: ont_4_book_test_405 → Unique triples extracted: 2\n",
      "[406/1500] ID: ont_4_book_test_406 → Unique triples extracted: 2\n",
      "[407/1500] ID: ont_4_book_test_407 → Unique triples extracted: 2\n",
      "[408/1500] ID: ont_4_book_test_408 → Unique triples extracted: 2\n",
      "Batch 408-415 inference time: 116.17 seconds\n",
      "[409/1500] ID: ont_4_book_test_409 → Unique triples extracted: 1\n",
      "[410/1500] ID: ont_4_book_test_410 → Unique triples extracted: 34\n",
      "[411/1500] ID: ont_4_book_test_411 → Unique triples extracted: 9\n",
      "[412/1500] ID: ont_4_book_test_412 → Unique triples extracted: 1\n",
      "[413/1500] ID: ont_4_book_test_413 → Unique triples extracted: 1\n",
      "[414/1500] ID: ont_4_book_test_414 → Unique triples extracted: 45\n",
      "[415/1500] ID: ont_4_book_test_415 → Unique triples extracted: 1\n",
      "[416/1500] ID: ont_4_book_test_416 → Unique triples extracted: 1\n",
      "Batch 416-423 inference time: 159.70 seconds\n",
      "[417/1500] ID: ont_4_book_test_417 → Unique triples extracted: 2\n",
      "[418/1500] ID: ont_4_book_test_418 → Unique triples extracted: 1\n",
      "[419/1500] ID: ont_4_book_test_419 → Unique triples extracted: 1\n",
      "[420/1500] ID: ont_4_book_test_420 → Unique triples extracted: 1\n",
      "[421/1500] ID: ont_4_book_test_421 → Unique triples extracted: 12\n",
      "[422/1500] ID: ont_4_book_test_422 → Unique triples extracted: 1\n",
      "[423/1500] ID: ont_4_book_test_423 → Unique triples extracted: 4\n",
      "[424/1500] ID: ont_4_book_test_424 → Unique triples extracted: 3\n",
      "Batch 424-431 inference time: 165.93 seconds\n",
      "[425/1500] ID: ont_4_book_test_425 → Unique triples extracted: 1\n",
      "[426/1500] ID: ont_4_book_test_426 → Unique triples extracted: 1\n",
      "[427/1500] ID: ont_4_book_test_427 → Unique triples extracted: 2\n",
      "[428/1500] ID: ont_4_book_test_428 → Unique triples extracted: 7\n",
      "[429/1500] ID: ont_4_book_test_429 → Unique triples extracted: 13\n",
      "[430/1500] ID: ont_4_book_test_430 → Unique triples extracted: 1\n",
      "[431/1500] ID: ont_4_book_test_431 → Unique triples extracted: 3\n",
      "[432/1500] ID: ont_4_book_test_432 → Unique triples extracted: 1\n",
      "Batch 432-439 inference time: 181.91 seconds\n",
      "[433/1500] ID: ont_4_book_test_433 → Unique triples extracted: 5\n",
      "[434/1500] ID: ont_4_book_test_434 → Unique triples extracted: 1\n",
      "[435/1500] ID: ont_4_book_test_435 → Unique triples extracted: 4\n",
      "[436/1500] ID: ont_4_book_test_436 → Unique triples extracted: 1\n",
      "[437/1500] ID: ont_4_book_test_437 → Unique triples extracted: 4\n",
      "[438/1500] ID: ont_4_book_test_438 → Unique triples extracted: 2\n",
      "[439/1500] ID: ont_4_book_test_439 → Unique triples extracted: 4\n",
      "[440/1500] ID: ont_4_book_test_440 → Unique triples extracted: 0\n",
      "Batch 440-447 inference time: 181.48 seconds\n",
      "[441/1500] ID: ont_4_book_test_441 → Unique triples extracted: 9\n",
      "[442/1500] ID: ont_4_book_test_442 → Unique triples extracted: 4\n",
      "[443/1500] ID: ont_4_book_test_443 → Unique triples extracted: 1\n",
      "[444/1500] ID: ont_4_book_test_444 → Unique triples extracted: 1\n",
      "[445/1500] ID: ont_4_book_test_445 → Unique triples extracted: 24\n",
      "[446/1500] ID: ont_4_book_test_446 → Unique triples extracted: 2\n",
      "[447/1500] ID: ont_4_book_test_447 → Unique triples extracted: 9\n",
      "[448/1500] ID: ont_4_book_test_448 → Unique triples extracted: 5\n",
      "Batch 448-455 inference time: 159.66 seconds\n",
      "[449/1500] ID: ont_4_book_test_449 → Unique triples extracted: 8\n",
      "[450/1500] ID: ont_4_book_test_450 → Unique triples extracted: 9\n",
      "[451/1500] ID: ont_4_book_test_451 → Unique triples extracted: 7\n",
      "[452/1500] ID: ont_4_book_test_452 → Unique triples extracted: 4\n",
      "[453/1500] ID: ont_4_book_test_453 → Unique triples extracted: 1\n",
      "[454/1500] ID: ont_4_book_test_454 → Unique triples extracted: 8\n",
      "[455/1500] ID: ont_4_book_test_455 → Unique triples extracted: 4\n",
      "[456/1500] ID: ont_4_book_test_456 → Unique triples extracted: 1\n",
      "Batch 456-463 inference time: 139.15 seconds\n",
      "[457/1500] ID: ont_4_book_test_457 → Unique triples extracted: 2\n",
      "[458/1500] ID: ont_4_book_test_458 → Unique triples extracted: 1\n",
      "[459/1500] ID: ont_4_book_test_459 → Unique triples extracted: 4\n",
      "[460/1500] ID: ont_4_book_test_460 → Unique triples extracted: 1\n",
      "[461/1500] ID: ont_4_book_test_461 → Unique triples extracted: 11\n",
      "[462/1500] ID: ont_4_book_test_462 → Unique triples extracted: 8\n",
      "[463/1500] ID: ont_4_book_test_463 → Unique triples extracted: 1\n",
      "[464/1500] ID: ont_4_book_test_464 → Unique triples extracted: 13\n",
      "Batch 464-471 inference time: 159.95 seconds\n",
      "[465/1500] ID: ont_4_book_test_465 → Unique triples extracted: 7\n",
      "[466/1500] ID: ont_4_book_test_466 → Unique triples extracted: 6\n",
      "[467/1500] ID: ont_4_book_test_467 → Unique triples extracted: 2\n",
      "[468/1500] ID: ont_4_book_test_468 → Unique triples extracted: 24\n",
      "[469/1500] ID: ont_4_book_test_469 → Unique triples extracted: 2\n",
      "[470/1500] ID: ont_4_book_test_470 → Unique triples extracted: 1\n",
      "[471/1500] ID: ont_4_book_test_471 → Unique triples extracted: 1\n",
      "[472/1500] ID: ont_4_book_test_472 → Unique triples extracted: 4\n",
      "Batch 472-479 inference time: 180.87 seconds\n",
      "[473/1500] ID: ont_4_book_test_473 → Unique triples extracted: 2\n",
      "[474/1500] ID: ont_4_book_test_474 → Unique triples extracted: 12\n",
      "[475/1500] ID: ont_4_book_test_475 → Unique triples extracted: 1\n",
      "[476/1500] ID: ont_4_book_test_476 → Unique triples extracted: 1\n",
      "[477/1500] ID: ont_4_book_test_477 → Unique triples extracted: 10\n",
      "[478/1500] ID: ont_4_book_test_478 → Unique triples extracted: 22\n",
      "[479/1500] ID: ont_4_book_test_479 → Unique triples extracted: 2\n",
      "[480/1500] ID: ont_4_book_test_480 → Unique triples extracted: 7\n",
      "Batch 480-487 inference time: 159.20 seconds\n",
      "[481/1500] ID: ont_4_book_test_481 → Unique triples extracted: 2\n",
      "[482/1500] ID: ont_4_book_test_482 → Unique triples extracted: 1\n",
      "[483/1500] ID: ont_4_book_test_483 → Unique triples extracted: 1\n",
      "[484/1500] ID: ont_4_book_test_484 → Unique triples extracted: 6\n",
      "[485/1500] ID: ont_4_book_test_485 → Unique triples extracted: 4\n",
      "[486/1500] ID: ont_4_book_test_486 → Unique triples extracted: 2\n",
      "[487/1500] ID: ont_4_book_test_487 → Unique triples extracted: 1\n",
      "[488/1500] ID: ont_4_book_test_488 → Unique triples extracted: 1\n",
      "Batch 488-495 inference time: 139.15 seconds\n",
      "[489/1500] ID: ont_4_book_test_489 → Unique triples extracted: 2\n",
      "[490/1500] ID: ont_4_book_test_490 → Unique triples extracted: 1\n",
      "[491/1500] ID: ont_4_book_test_491 → Unique triples extracted: 3\n",
      "[492/1500] ID: ont_4_book_test_492 → Unique triples extracted: 12\n",
      "[493/1500] ID: ont_4_book_test_493 → Unique triples extracted: 2\n",
      "[494/1500] ID: ont_4_book_test_494 → Unique triples extracted: 1\n",
      "[495/1500] ID: ont_4_book_test_495 → Unique triples extracted: 11\n",
      "[496/1500] ID: ont_4_book_test_496 → Unique triples extracted: 2\n",
      "Batch 496-503 inference time: 137.19 seconds\n",
      "[497/1500] ID: ont_4_book_test_497 → Unique triples extracted: 1\n",
      "[498/1500] ID: ont_4_book_test_498 → Unique triples extracted: 1\n",
      "[499/1500] ID: ont_4_book_test_499 → Unique triples extracted: 7\n",
      "[500/1500] ID: ont_4_book_test_500 → Unique triples extracted: 2\n",
      "[501/1500] ID: ont_4_book_test_501 → Unique triples extracted: 1\n",
      "[502/1500] ID: ont_4_book_test_502 → Unique triples extracted: 17\n",
      "[503/1500] ID: ont_4_book_test_503 → Unique triples extracted: 1\n",
      "[504/1500] ID: ont_4_book_test_504 → Unique triples extracted: 7\n",
      "Batch 504-511 inference time: 180.91 seconds\n",
      "[505/1500] ID: ont_4_book_test_505 → Unique triples extracted: 2\n",
      "[506/1500] ID: ont_4_book_test_506 → Unique triples extracted: 10\n",
      "[507/1500] ID: ont_4_book_test_507 → Unique triples extracted: 1\n",
      "[508/1500] ID: ont_4_book_test_508 → Unique triples extracted: 0\n",
      "[509/1500] ID: ont_4_book_test_509 → Unique triples extracted: 1\n",
      "[510/1500] ID: ont_4_book_test_510 → Unique triples extracted: 1\n",
      "[511/1500] ID: ont_4_book_test_511 → Unique triples extracted: 0\n",
      "[512/1500] ID: ont_4_book_test_512 → Unique triples extracted: 8\n",
      "Batch 512-519 inference time: 116.24 seconds\n",
      "[513/1500] ID: ont_4_book_test_513 → Unique triples extracted: 2\n",
      "[514/1500] ID: ont_4_book_test_514 → Unique triples extracted: 3\n",
      "[515/1500] ID: ont_4_book_test_515 → Unique triples extracted: 1\n",
      "[516/1500] ID: ont_4_book_test_516 → Unique triples extracted: 1\n",
      "[517/1500] ID: ont_4_book_test_517 → Unique triples extracted: 17\n",
      "[518/1500] ID: ont_4_book_test_518 → Unique triples extracted: 1\n",
      "[519/1500] ID: ont_4_book_test_519 → Unique triples extracted: 2\n",
      "[520/1500] ID: ont_4_book_test_520 → Unique triples extracted: 1\n",
      "Batch 520-527 inference time: 158.57 seconds\n",
      "[521/1500] ID: ont_4_book_test_521 → Unique triples extracted: 4\n",
      "[522/1500] ID: ont_4_book_test_522 → Unique triples extracted: 1\n",
      "[523/1500] ID: ont_4_book_test_523 → Unique triples extracted: 2\n",
      "[524/1500] ID: ont_4_book_test_524 → Unique triples extracted: 1\n",
      "[525/1500] ID: ont_4_book_test_525 → Unique triples extracted: 2\n",
      "[526/1500] ID: ont_4_book_test_526 → Unique triples extracted: 1\n",
      "[527/1500] ID: ont_4_book_test_527 → Unique triples extracted: 1\n",
      "[528/1500] ID: ont_4_book_test_528 → Unique triples extracted: 1\n",
      "Batch 528-535 inference time: 157.32 seconds\n",
      "[529/1500] ID: ont_4_book_test_529 → Unique triples extracted: 8\n",
      "[530/1500] ID: ont_4_book_test_530 → Unique triples extracted: 3\n",
      "[531/1500] ID: ont_4_book_test_531 → Unique triples extracted: 10\n",
      "[532/1500] ID: ont_4_book_test_532 → Unique triples extracted: 18\n",
      "[533/1500] ID: ont_4_book_test_533 → Unique triples extracted: 9\n",
      "[534/1500] ID: ont_4_book_test_534 → Unique triples extracted: 1\n",
      "[535/1500] ID: ont_4_book_test_535 → Unique triples extracted: 9\n",
      "[536/1500] ID: ont_4_book_test_536 → Unique triples extracted: 1\n",
      "Batch 536-543 inference time: 158.65 seconds\n",
      "[537/1500] ID: ont_4_book_test_537 → Unique triples extracted: 14\n",
      "[538/1500] ID: ont_4_book_test_538 → Unique triples extracted: 4\n",
      "[539/1500] ID: ont_4_book_test_539 → Unique triples extracted: 1\n",
      "[540/1500] ID: ont_4_book_test_540 → Unique triples extracted: 1\n",
      "[541/1500] ID: ont_4_book_test_541 → Unique triples extracted: 0\n",
      "[542/1500] ID: ont_4_book_test_542 → Unique triples extracted: 1\n",
      "[543/1500] ID: ont_4_book_test_543 → Unique triples extracted: 6\n",
      "[544/1500] ID: ont_4_book_test_544 → Unique triples extracted: 1\n",
      "Batch 544-549 inference time: 91.29 seconds\n",
      "[545/1500] ID: ont_4_book_test_545 → Unique triples extracted: 1\n",
      "[546/1500] ID: ont_4_book_test_546 → Unique triples extracted: 10\n",
      "[547/1500] ID: ont_4_book_test_547 → Unique triples extracted: 10\n",
      "[548/1500] ID: ont_4_book_test_548 → Unique triples extracted: 1\n",
      "[549/1500] ID: ont_4_book_test_549 → Unique triples extracted: 1\n",
      "[550/1500] ID: ont_4_book_test_550 → Unique triples extracted: 8\n",
      "\n",
      "✅ All 550 prompts processed. Results saved to: /upb/users/b/balram/profiles/unix/cs/Text2KG/withont/data/wikidata/response/Llama3/cot_response_without_quant_batch/ont_4_book_llm_response_improved_batch_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = '/upb/users/b/balram/profiles/unix/cs/Text2KG/withont/data/wikidata/input_prompts/cot_prompts/ont_5_military_prompts_improved.jsonl'\n",
    "    output_file = \"/upb/users/b/balram/profiles/unix/cs/Text2KG/withont/data/wikidata/response/Llama3/cot_response_without_quant_batch/ont_5_military_llm_response_improved.jsonl\"\n",
    "    text_pipe, tokenizer = setup_model(\"meta-llama/Meta-Llama-3-8B\")\n",
    "    main(input_file, output_file, text_pipe, tokenizer, num_prompts=1500, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a6e75-bdea-49e9-88cf-e4b59bf3f5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e2d44-032c-43c6-8ef0-d446478a14fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc10576-aea3-4043-9bd0-b9586bdf24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = '/upb/users/b/balram/profiles/unix/cs/Text2KG/withont/data/dbpedia_webnig/input_prompts/cot_prompts/ont_19_film_prompts_improved.jsonl'\n",
    "    output_file = \"/upb/users/b/balram/profiles/unix/cs/Text2KG/withont/data/dbpedia_webnig/response/Llama3/cot_response_without_quant_batch/ont_19_film_llm_response_improved.jsonl\"\n",
    "    text_pipe, tokenizer = setup_model(\"meta-llama/Meta-Llama-3-8B\")\n",
    "    main(input_file, output_file, text_pipe, tokenizer, num_prompts=1500, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e21bf3-a419-4cf3-b0de-3e51528508bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KG Pipeline (GPU)",
   "language": "python",
   "name": "kg_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
